---
layout:     post   				    # 使用的布局（不需要改）
title:      4.1 cq 				# 标题 
subtitle:    #副标题
date:       2018-04-16				# 时间
author:     Manlin 						# 作者
header-img: img/post-bg-coffee.jpeg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
- trading
- backtesting
---


# Question 2：求偏度


```python
import tushare as ts
import numpy as np
import pandas as pd
import math
import matplotlib.pyplot as plt
```


```python
#沪深300成分股
hs300_code = list(ts.get_hs300s().code)

#get history data
start = '2017-10-13'
end = '2018-04-13'
d1 = {}
for code in hs300_code:
    d1[code] = ts.get_hist_data(code,start,end)

#remove None and empy dataframe
for code in hs300_code:
    if (d1[code] is None) or d1[code].empty:
        d1.pop(code)
```


```python
d1_keys = list(d1.keys())
d2 = {}
for code in d1_keys:
    d2[code] = d1[code].p_change
df1 = pd.DataFrame(d2)
df1.head()
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>000001</th>
      <th>000002</th>
      <th>000008</th>
      <th>000060</th>
      <th>000063</th>
      <th>000069</th>
      <th>000100</th>
      <th>000157</th>
      <th>000166</th>
      <th>000333</th>
      <th>...</th>
      <th>601878</th>
      <th>601881</th>
      <th>601888</th>
      <th>601898</th>
      <th>601899</th>
      <th>601901</th>
      <th>601919</th>
      <th>601933</th>
      <th>601939</th>
      <th>601958</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-10-13</th>
      <td>-1.65</td>
      <td>-0.63</td>
      <td>-1.32</td>
      <td>0.17</td>
      <td>1.13</td>
      <td>3.17</td>
      <td>2.17</td>
      <td>0.64</td>
      <td>0.34</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.49</td>
      <td>1.35</td>
      <td>0.39</td>
      <td>0.48</td>
      <td>0.78</td>
      <td>0.46</td>
      <td>-0.57</td>
      <td>0.92</td>
      <td>-0.57</td>
      <td>0.97</td>
    </tr>
    <tr>
      <th>2017-10-16</th>
      <td>2.02</td>
      <td>-2.30</td>
      <td>2.22</td>
      <td>1.01</td>
      <td>3.22</td>
      <td>-1.42</td>
      <td>3.19</td>
      <td>-0.85</td>
      <td>-1.02</td>
      <td>-1.76</td>
      <td>...</td>
      <td>-2.13</td>
      <td>-2.20</td>
      <td>-1.07</td>
      <td>0.00</td>
      <td>2.82</td>
      <td>-0.69</td>
      <td>1.30</td>
      <td>1.71</td>
      <td>1.42</td>
      <td>0.84</td>
    </tr>
    <tr>
      <th>2017-10-17</th>
      <td>-0.69</td>
      <td>-0.38</td>
      <td>-0.11</td>
      <td>-2.83</td>
      <td>0.03</td>
      <td>0.00</td>
      <td>3.35</td>
      <td>0.00</td>
      <td>-0.17</td>
      <td>2.80</td>
      <td>...</td>
      <td>-4.44</td>
      <td>-1.50</td>
      <td>0.25</td>
      <td>-0.96</td>
      <td>-2.49</td>
      <td>-0.93</td>
      <td>-0.85</td>
      <td>0.00</td>
      <td>-0.70</td>
      <td>-2.14</td>
    </tr>
    <tr>
      <th>2017-10-18</th>
      <td>1.56</td>
      <td>0.84</td>
      <td>0.33</td>
      <td>-1.20</td>
      <td>0.56</td>
      <td>1.08</td>
      <td>4.99</td>
      <td>-1.28</td>
      <td>0.34</td>
      <td>1.21</td>
      <td>...</td>
      <td>-3.57</td>
      <td>-0.90</td>
      <td>0.80</td>
      <td>-1.94</td>
      <td>0.51</td>
      <td>-1.87</td>
      <td>0.57</td>
      <td>-0.78</td>
      <td>2.26</td>
      <td>-1.82</td>
    </tr>
    <tr>
      <th>2017-10-19</th>
      <td>-0.51</td>
      <td>-1.44</td>
      <td>-1.84</td>
      <td>-2.00</td>
      <td>-7.35</td>
      <td>0.24</td>
      <td>-1.19</td>
      <td>-1.95</td>
      <td>-1.88</td>
      <td>-0.20</td>
      <td>...</td>
      <td>-2.57</td>
      <td>-4.68</td>
      <td>2.17</td>
      <td>-2.48</td>
      <td>0.25</td>
      <td>-2.98</td>
      <td>-1.43</td>
      <td>3.27</td>
      <td>0.69</td>
      <td>-0.99</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 284 columns</p>
</div>




```python
#df1 = df.dropna(axis=1,how='any')  
sk= df1.skew(skipna=True)
df2=pd.DataFrame(sk,columns=['skewness'])
df2.head()
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>skewness</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>000001</th>
      <td>0.069492</td>
    </tr>
    <tr>
      <th>000002</th>
      <td>0.731529</td>
    </tr>
    <tr>
      <th>000008</th>
      <td>0.745523</td>
    </tr>
    <tr>
      <th>000060</th>
      <td>-1.126415</td>
    </tr>
    <tr>
      <th>000063</th>
      <td>-0.488220</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.subplot(1,2,1)
df2['skewness'].plot(figsize=(20,6),label='Skewness')
plt.legend()

plt.subplot(1,2,2)
plt.hist(df2['skewness'],bins=50,label='Frequency of Skewness')
plt.legend()

plt.show()
#np.sum(df2<0)/df2.count()
```


![png](output_5_0.png)


## Answer 2: 

### 2017-10-13至2018-04-12半年内，沪深300成分股偏度为负值的偏多。282个股票中，偏度为负占62.4%。
### 经过验证，2015-01-01至2015-06-15这半年内，偏度为负仅占38.5%。
### 所以初步推测，这个问题的答案应该是需要根据时间段而异，在牛市时股票收益率出现右偏的概率比较大，因为产生极端正收益率的概率高于正常水平，右偏肥尾。而市场情绪不好时左偏的概率大一些，因为极端负收益的概率高于正常水平。

# Question 3: 最后一位数字频率


```python
d3 = {}
for code in d1_keys:
    d3[code] = d1[code].close
df3 = pd.DataFrame(d3)
```


```python
df4=df3.dropna(axis=1,how='any')
df5=(df4*100%10).applymap(int)

df0=pd.DataFrame()
for code in list(df5.keys()):
    df0=df0.append(df5[code].value_counts().sort_index())
```


```python
print('百分位平均频率: ')
print(df0.mean())
```

    百分位平均频率: 
    0    16.145161
    1    11.342742
    2    11.673387
    3    11.379032
    4    11.310484
    5    12.649194
    6    11.334677
    7    11.310484
    8    13.145161
    9    12.709677
    dtype: float64



```python
df55=(df4%10).applymap(int)
df00=pd.DataFrame()
for code in list(df55.keys()):
    df00=df00.append(df55[code].value_counts().sort_index())
df00.T
df00.mean()
print('个位数平均频率: ')
print(df00.mean())
```

    个位数平均频率: 
    0    17.489933
    1    16.601399
    2    17.726619
    3    22.565217
    4    20.654676
    5    21.090278
    6    23.631579
    7    22.890244
    8    21.862500
    9    20.606452
    dtype: float64



```python
md=ts.get_hist_data('000333',start='2017-01-01',end='2018-04-13')
mddf=pd.DataFrame(md.close)

g=(mddf%10).applymap(int)
print('美的集团--个位数频率：')
print(g['close'].value_counts().sort_index())

mddf.plot().invert_xaxis()
plt.show()
```

    美的集团--个位数频率：
    0    37
    1    44
    2    43
    3    37
    4    33
    5    25
    6    22
    7    14
    8    19
    9    39
    Name: close, dtype: int64



![png](output_12_1.png)


## Answer 3:

### 百分位数与个位数出现频率似乎区别并不明显，可能是半年的样本数据量不够大。
### 但是百分位统计结果出现0的概率远高于其他数字，似乎是tushare数据不精确，对最后一位做了归0处理。而除了0以外，发现出现8的概率最大，出现4与7的概率最小，所以可能是因为迷信……?

### 但对于个位数，我猜测出现频率最高的的数字是因为阻力点与支撑点出现在附近，随机选择‘美的集团000333’分析，个位数1与2左右频率比较高，看图确实在41，51，61左右有阻力与支撑。


```python

```
